{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o4agPCtDC-MS"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
        "import torchvision\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        ")  # Gives easier dataset managment and creates mini batches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CatsAndDogsDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
        "        image = Image.open(img_path)\n",
        "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, y_label)\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "in_channel = 3\n",
        "num_classes = 2\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "\n",
        "# Load Data\n",
        "dataset = CatsAndDogsDataset(\n",
        "    csv_file=\"/content/drive/MyDrive/cats_dogs.csv\",\n",
        "    root_dir=\"/content/drive/MyDrive/cats_dogs_resized\",\n",
        "    transform=transforms.Compose([\n",
        "                         transforms.Resize((224, 224)),\n",
        "                         transforms.ToTensor(),\n",
        "                         transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "                     ]),\n",
        ")\n",
        "\n",
        "# Dataset is actually a lot larger ~25k images, just took out 10 pictures\n",
        "# to upload to Github. It's enough to understand the structure and scale\n",
        "# if you got more images.\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [5, 5])\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Model\n",
        "model = torchvision.models.googlenet(weights=\"DEFAULT\")\n",
        "\n",
        "# freeze all layers, change final linear layer with num_classes\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# final layer is not frozen\n",
        "model.fc = nn.Linear(in_features=1024, out_features=num_classes)\n",
        "model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    losses = []\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n",
        "\n",
        "# Check accuracy on training to see how good our model is\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "        print(\n",
        "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
        "        )\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "print(\"Checking accuracy on Training Set\")\n",
        "check_accuracy(train_loader, model)\n",
        "\n",
        "print(\"Checking accuracy on Test Set\")\n",
        "check_accuracy(test_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__JK0_uiE6Fb",
        "outputId": "0cc937fa-ccf4-4fe6-b192-58eb51575e18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost at epoch 0 is 0.5598849058151245\n",
            "Cost at epoch 1 is 0.4990479350090027\n",
            "Cost at epoch 2 is 0.48527565598487854\n",
            "Cost at epoch 3 is 0.46390658617019653\n",
            "Cost at epoch 4 is 0.4529189169406891\n",
            "Cost at epoch 5 is 0.36936062574386597\n",
            "Cost at epoch 6 is 0.38300055265426636\n",
            "Cost at epoch 7 is 0.355146586894989\n",
            "Cost at epoch 8 is 0.36729347705841064\n",
            "Cost at epoch 9 is 0.37553396821022034\n",
            "Checking accuracy on Training Set\n",
            "Got 4 / 5 with accuracy 80.00\n",
            "Checking accuracy on Test Set\n",
            "Got 4 / 5 with accuracy 80.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/code/adinishad/pytorch-cats-and-dogs-classification"
      ],
      "metadata": {
        "id": "sjdlUvOEJfSM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft_jeEajD52g",
        "outputId": "4c73a4cb-4e60-4892-8bdf-b3f65363823c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9lVyk9jtI94l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference"
      ],
      "metadata": {
        "id": "JjPe4wnHJr6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RandomImagePrediction(filepath):\n",
        "    img_array = Image.open(filepath).convert(\"RGB\")\n",
        "    data_transforms=transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "    ])\n",
        "    img = data_transforms(img_array).unsqueeze(dim=0) # Returns a new tensor with a dimension of size one inserted at the specified position.\n",
        "    load = DataLoader(img)\n",
        "\n",
        "    for x in load:\n",
        "        x=x.to(device)\n",
        "        pred = model(x)\n",
        "        _, preds = torch.max(pred, 1)\n",
        "        print(f\"class : {preds}\")\n",
        "        if preds[0] == 1: print(f\"predicted ----> Dog\")\n",
        "        else: print(f\"predicted ----> Cat\")"
      ],
      "metadata": {
        "id": "BbXPsU7TI9-j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RandomImagePrediction(\"/content/drive/MyDrive/cat_dogs/cats/cat.1.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyv9P8haJfyz",
        "outputId": "56f43d1d-47c9-4414-b0f7-d2f927287c90"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class : tensor([0])\n",
            "predicted ----> Cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x ./get_data.sh"
      ],
      "metadata": {
        "id": "2fOJURD0JlfW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./get_data.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CluDDnsKqYy",
        "outputId": "37773e80-1799-4aa5-cfbd-fb8aa2b7650c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-17 15:43:50--  https://www.kaggle.com/datasets/e1cd22253a9b23b073794872bf565648ddbe4f17e7fa9e74766ad3707141adeb/download?datasetVersionNumber=1\n",
            "Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n",
            "Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /account/login?titleType=dataset-downloads&showDatasetDownloadSkip=False&messageId=datasetsWelcome&returnUrl=%2Fdatasets%2Fe1cd22253a9b23b073794872bf565648ddbe4f17e7fa9e74766ad3707141adeb%2Fversions%2F1%3Fresource%3Ddownload [following]\n",
            "--2023-08-17 15:43:50--  https://www.kaggle.com/account/login?titleType=dataset-downloads&showDatasetDownloadSkip=False&messageId=datasetsWelcome&returnUrl=%2Fdatasets%2Fe1cd22253a9b23b073794872bf565648ddbe4f17e7fa9e74766ad3707141adeb%2Fversions%2F1%3Fresource%3Ddownload\n",
            "Reusing existing connection to www.kaggle.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘download?datasetVersionNumber=1’\n",
            "\n",
            "download?datasetVer     [ <=>                ]   4.76K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-08-17 15:43:50 (393 KB/s) - ‘download?datasetVersionNumber=1’ saved [4873]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UU23NXlvKtBM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}