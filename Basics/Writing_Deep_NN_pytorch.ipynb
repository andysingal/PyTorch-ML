{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Writing Deep NN pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbRAWNvoZLr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ubuiquRIg7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_in,n_h,n_out,batch_size = 10, 5, 1, 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--ZtIR6YIqTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn(batch_size, n_in)\n",
        "y = torch.tensor([[1.0], [1.0], [0.0], [1.0], [0.0], [1.0], [0.0], [1.0], [1.0], [0.0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdUbmcWgI8m7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build the model\n",
        "model = nn.Sequential(nn.Linear(n_in,n_h),\n",
        "                     nn.ReLU(),\n",
        "                     nn.Linear(n_h,n_out),\n",
        "                     nn.Sigmoid())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rcIGpwZJRiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-cQluxNJZdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters() , lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ticifz0nJj8L",
        "colab_type": "code",
        "outputId": "89beefaa-782a-4838-bd54-ca31d04714eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "#Gradient Descent\n",
        "for i in range(25):\n",
        "  y_pred = model(x)\n",
        "  loss = loss_func(y_pred,y)\n",
        "  \n",
        "  print('epoch : ',(i+1), ' loss: ',loss.item())\n",
        "  #backward\n",
        "  loss.backward()\n",
        "  \n",
        "  #Update the parameters\n",
        "  optimizer.step() #Updates all the parameters\n",
        "  \n",
        "  #Zero Gradients\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  #This will execute until total number of epochs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch :  1  loss:  0.25127312541007996\n",
            "epoch :  2  loss:  0.2511797249317169\n",
            "epoch :  3  loss:  0.25108638405799866\n",
            "epoch :  4  loss:  0.25099316239356995\n",
            "epoch :  5  loss:  0.250900000333786\n",
            "epoch :  6  loss:  0.2508069574832916\n",
            "epoch :  7  loss:  0.250713974237442\n",
            "epoch :  8  loss:  0.25062108039855957\n",
            "epoch :  9  loss:  0.2505282759666443\n",
            "epoch :  10  loss:  0.25043556094169617\n",
            "epoch :  11  loss:  0.2503429055213928\n",
            "epoch :  12  loss:  0.25025036931037903\n",
            "epoch :  13  loss:  0.25015789270401\n",
            "epoch :  14  loss:  0.25006547570228577\n",
            "epoch :  15  loss:  0.24997316300868988\n",
            "epoch :  16  loss:  0.24988092482089996\n",
            "epoch :  17  loss:  0.2497887760400772\n",
            "epoch :  18  loss:  0.24969668686389923\n",
            "epoch :  19  loss:  0.24960468709468842\n",
            "epoch :  20  loss:  0.24951274693012238\n",
            "epoch :  21  loss:  0.2494208812713623\n",
            "epoch :  22  loss:  0.2493290901184082\n",
            "epoch :  23  loss:  0.24923740327358246\n",
            "epoch :  24  loss:  0.2491457611322403\n",
            "epoch :  25  loss:  0.2490542083978653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bQa9MbQYlnb",
        "colab_type": "text"
      },
      "source": [
        "# Custom NN Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXQyOE8RZPbb",
        "colab_type": "text"
      },
      "source": [
        "With the use of torch.nn.module we can combine many simple layers to implement complex neural networks.\n",
        "\n",
        "In other words, we can use it to represent an arbitary function *f* in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsSbD9TdYlPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "We subclass torch.nn.module for complex networks.\n",
        "\n",
        "We override methods under --> torch.nn.module class\n",
        "\n",
        "  1. __init__ function :\n",
        "          - invoked when we create instance of nn.Module\n",
        "         \n",
        "  2. forward function:\n",
        "          - We define how output will be computed\n",
        "\"\"\";"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7f9S-xGKqvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class custom_class(nn.Module):\n",
        "  def __init__(self,n_in,n_h,n_out):\n",
        "    super(custom_class,self).__init__()\n",
        "    self.model = nn.Sequential(nn.Linear(n_in,n_h),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Linear(n_h,n_out),\n",
        "                              nn.Sigmoid())\n",
        " \n",
        "  def forward(self,x):\n",
        "    return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00oetTHbbQs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_nn = custom_class(n_in,n_h,n_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tf3DrwmcjqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(custom_nn.parameters() , lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7ZzJ9iGeHJp",
        "colab_type": "code",
        "outputId": "abfd645f-ca90-492e-c7d9-8bdad3155531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "#Gradient Descent\n",
        "for i in range(25):\n",
        "  y_pred = custom_nn(x) # instead of model(x) , we replace with custom_nn(x)\n",
        "  loss = loss_func(y_pred,y)\n",
        "  \n",
        "  print('epoch : ',(i+1), ' loss: ',loss.item())\n",
        "  #backward\n",
        "  loss.backward()\n",
        "  \n",
        "  #Update the parameters\n",
        "  optimizer.step() #Updates all the parameters\n",
        "  \n",
        "  #Zero Gradients\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  #This will execute until total number of epochs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch :  1  loss:  0.21848411858081818\n",
            "epoch :  2  loss:  0.2183840274810791\n",
            "epoch :  3  loss:  0.2182837277650833\n",
            "epoch :  4  loss:  0.2181832492351532\n",
            "epoch :  5  loss:  0.21808262169361115\n",
            "epoch :  6  loss:  0.21798177063465118\n",
            "epoch :  7  loss:  0.2178807556629181\n",
            "epoch :  8  loss:  0.21777954697608948\n",
            "epoch :  9  loss:  0.21767815947532654\n",
            "epoch :  10  loss:  0.21757657825946808\n",
            "epoch :  11  loss:  0.2174748182296753\n",
            "epoch :  12  loss:  0.217372864484787\n",
            "epoch :  13  loss:  0.21727071702480316\n",
            "epoch :  14  loss:  0.21716837584972382\n",
            "epoch :  15  loss:  0.21706585586071014\n",
            "epoch :  16  loss:  0.21696673333644867\n",
            "epoch :  17  loss:  0.21687619388103485\n",
            "epoch :  18  loss:  0.2167855203151703\n",
            "epoch :  19  loss:  0.21669472754001617\n",
            "epoch :  20  loss:  0.21660377085208893\n",
            "epoch :  21  loss:  0.21651265025138855\n",
            "epoch :  22  loss:  0.21642139554023743\n",
            "epoch :  23  loss:  0.21633002161979675\n",
            "epoch :  24  loss:  0.21623848378658295\n",
            "epoch :  25  loss:  0.2161467969417572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFMFhaP_eSLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}